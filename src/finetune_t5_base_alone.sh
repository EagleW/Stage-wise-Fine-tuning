python finetune_t5.py \
--data_dir=pos \
--gpus 1 \
--learning_rate=3e-5 \
--output_dir=t5_base_results \
--num_train_epochs 15 \
--train_batch_size 32 --eval_batch_size 64 \
--max_source_length=150 \
--max_target_length=100 \
--val_max_target_length=100 \
--test_max_target_length=100 \
--eval_max_gen_length=100 \
--model_name_or_path t5-base \
--task rdf2text \
--do_train \
--early_stopping_patience 15 \
--warmup_steps 2 \
--do_predict \
--lr_scheduler cosine_w_restarts \
--eval_beams 3
 "$@"
