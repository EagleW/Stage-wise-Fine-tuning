# Automatic Evaluation for WebNLG Challenge 2017
Automatic scripts used to evaluate the WebNLG Challenge submissions.

_The WebNLG Challenge: Generating Text from RDF Data_. C. Gardent, A. Shimorina, S. Narayan, L. Perez-Beltrachini. Proceedings of INLG 2017. [[pdf](https://www.aclweb.org/anthology/W17-3518)]

Evaluation scripts calculate automatic scores for the whole submissions, for seen and unseen categories, for different categories (Monument, Artist, etc.) and for different sizes of triplesets (1-7). 

1. Run `python3 evaluation.py` to preprocess submission files and to generate reference files for automatic metric scorers.

    The files generated by that script are in `references/` and `teams/`.

2. Install scripts for METEOR, TER. See [guidelines provided on the baseline page](https://webnlg-challenge.loria.fr/challenge_2017/#webnlg-baseline-system).

3. Run `./bleu_eval_3ref.sh` to get BLEU scores.

    Scripts for METEOR and TER should be run from directories where the scorers are installed.

4. Run `./meteor_eval.sh` to get METEOR scores. You should modify the GLOBAL\_PATH variable. (METEOR scoring for all options may take around an hour.)
5. Run `./ter_eval.sh` to get TER scores. You should modify the GLOBAL\_PATH variable.

    The files generated by the scorers are in `eval/`.

## Statistical Significance
Test statistical significance by the bootstrapping algorithm from [Koehn and Monz, 2006](http://www.aclweb.org/anthology/W06-3114). For more info see this [readme](./significance-2005-DARPA-NIST/README.md).

1. Run `python3 significance_block_creation.py` to create blocks of 20 inputs.
	The script writes reference and submissions files to `references/metric_per_block/` and `teams/metric_per_block/`.

2. Calculate metrics for each block.
	```
    ./bleu_eval_3ref_per_block.sh
    ```
	Scripts for METEOR and TER should be run from directories where the scorers are installed. You should modify the GLOBAL\_PATH variables.
	```
	./meteor_eval_3ref_per_block.sh  # can take several hours
	./ter_eval_3ref_per_block.sh
	```
	The scripts write scores to `significance-2005-DARPA-NIST/`.

3. Test statistical significance.
	```
    cd significance-2005-DARPA-NIST/
	python3 significancetest_2005_darpa_nist.py
	```

	Files with results are in `significance-2005-DARPA-NIST/`.

